{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc90ee07",
   "metadata": {},
   "source": [
    "Writing the mlpf code  in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3f9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.nn as nn\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d10643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacf01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['/home/sraj/UCSD/particleflow/mlpf/']\n",
    "\n",
    "import tfmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274efacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘tev14_pythia8_ttbar_0_0.pkl.bz2’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate -nc https://zenodo.org/record/4452283/files/tev14_pythia8_ttbar_0_0.pkl.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f59894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(bz2.BZ2File(\"tev14_pythia8_ttbar_0_0.pkl.bz2\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb75f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 100 events in one file\n",
    "len(data['X']), len(data['ygen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pad the number of elements to a size that's divisible by the bins\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "max_size = 50*128\n",
    "\n",
    "for i in range(len(data['X'])):\n",
    "    X = data['X'][i][:max_size, :]\n",
    "    y = data['ygen'][i][:max_size, :]\n",
    "    Xpad = np.pad(X,[(0, max_size - X.shape[0]), (0,0)])\n",
    "    ypad = np.pad(y, [(0, max_size - y. shape[0]), (0,0)])\n",
    "    Xpad = Xpad.astype(np.float32)\n",
    "    ypad = ypad.astype(np.float32)\n",
    "    Xs.append(Xpad)\n",
    "    ys.append(ypad)\n",
    "    \n",
    "X = np.stack(Xs)\n",
    "y = np.stack(ys)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22525416",
   "metadata": {},
   "source": [
    "## Defining a tensorflow FCN class for particleflow\n",
    "Converting the pytorcgh into tensorflow, using this method which can be found using this link. link can be found [here](https://stackoverflow.com/questions/69148722/what-is-the-alias-to-pytorch-nn-module-in-tensorflow)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4c9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPF_FCN(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim = 12, hidden_dim = 2, embedding_dim=2, output_dim = 2):\n",
    "        super (MLPF_FCN, self).__init__()\n",
    "        \n",
    "        self.act = tf.nn.relu\n",
    "        \n",
    "        self.nn1 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim, hidden_dim),\n",
    "            tf.keras.layers.BatchNormalization(hidden_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, hidden_dim),\n",
    "            tf.keras.BatchNormalization(hidden_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        self.nn2 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim+embedding_dim, hidden_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, output_dim),\n",
    "        \n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        embedding = self.nn1(X)\n",
    "        return self.nn2(tf.concat([X, embedding], axis=1)), _, _\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13892054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the tensorflow GNN class for particleflow\n",
    "import pickle as pkl\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dca2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPF_GNN(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    GNN model based on Gravnet...\n",
    "\n",
    "    Forward pass returns\n",
    "        preds: tensor of predictions containing a concatenated representation of the pids and p4\n",
    "        A: dict() object containing adjacency matrices for each message passing\n",
    "        msg_activations: dict() object containing activations before each message passing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim =12, output_dim_id = 6, output_dim_p4 = 6, \n",
    "                embedding_dim = 2, hiddn_dim1 = 2, hidden_dim2 = 2, \n",
    "                num_convs=2, space_dim = 4, propagate_dim=2, k=8):\n",
    "        super(MLPF_GNN, self).__init__()\n",
    "        \n",
    "        self.act = tf.nn.elu\n",
    "        \n",
    "        #(1) embedding\n",
    "        \n",
    "        self.nn1 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim, hiddn_dim1),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, hiddn_dim1),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, hiddn_dim1),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        self.conv = tf.keras.layers.Layer()\n",
    "        for i in range(num_convs):\n",
    "            slef.conv.append(GravNetConv_LRP(embedding_dim, embedding_dim, space_dim, propagate_dim, k))\n",
    "            \n",
    "            \n",
    "        ##(3) DNN layer: classifying pid \n",
    "        self.nn2 =  tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim+embedding_dim, hiddn_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, hiddn_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, hiddn_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, embedding_dim),      \n",
    "        )\n",
    "            \n",
    "       # (4) DNN layer: regressing p4\n",
    "        self.nn3 = tf.keras.Sequentiall(\n",
    "            tf.keras.layers.Dense(input_dim + output_dim_id, hidden_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, output_dim_p4),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x0 = batch.x\n",
    "        \n",
    "        # embed the inputs\n",
    "        embedding = self.nn1(x0)\n",
    "        \n",
    "        # perform a series of graph convolutions\n",
    "        A = {}\n",
    "        msg_activations ={}\n",
    "        for num, conv in enumerate(self.conv):\n",
    "            embedding, A[f'conv.{num}'], msg_activations[f'conv.{num}'] = conv(embedding)\n",
    "        \n",
    "        # predict the pid's\n",
    "        preds_id = self.nn2(tf.concat([x0, embedding], axis=-1))\n",
    "        \n",
    "        # predict the p4's\n",
    "        preds_p4 = self.nn3(tf.concat([x0, preds_id], axis=-1))\n",
    "        \n",
    "        return tf.concat([preds_id, preds_p4], axis= -1),\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fe45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
