{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb2fd8a",
   "metadata": {},
   "source": [
    "This is based on the following link:\n",
    "<span style = \"font-size:larger;\"> <span style=\"color:red\">\n",
    "https://github.com/farakiko/particleflow/blob/master/notebooks/delphes-lrp-playground.ipynb\n",
    "</span></span> <br>\n",
    "Tasks(to be done under the Xai environment as [mentioned in this link](https://github.com/farakiko/xai4hep):-\n",
    "- [x] Install TensorFlow\n",
    "- [ ] Try to run the code in pytorch or in TensorFlow\n",
    "- [ ] start integrating the lrp work (which can be found under mlpf/lrp/lrp_mlpf.py) to work for a tensorflow model instead of a pytorch model... this essentially means copying the LRP_MLPF class to the notebook and trying to get this block to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db13bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "#pytorch libraries\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from typing import Optional, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10665a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"/home/sraj/UCSD/particleflow/mlpf/\"]\n",
    "\n",
    "import tfmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘tev14_pythia8_ttbar_0_0.pkl.bz2’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate -nc https://zenodo.org/record/4452283/files/tev14_pythia8_ttbar_0_0.pkl.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74646309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(bz2.BZ2File(\"tev14_pythia8_ttbar_0_0.pkl.bz2\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ca9858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 events in one file\n",
    "len(data[\"X\"]), len(data[\"ygen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e08b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad the number of elements to a size that's divisible by the bin size\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "max_size = 50*128\n",
    "for i in range(len(data[\"X\"])):\n",
    "    X = data[\"X\"][i][:max_size, :]\n",
    "    y = data[\"ygen\"][i][:max_size, :]\n",
    "    Xpad = np.pad(X, [(0, max_size - X.shape[0]), (0, 0)])\n",
    "    ypad = np.pad(y, [(0, max_size - y.shape[0]), (0, 0)])\n",
    "    Xpad = Xpad.astype(np.float32)\n",
    "    ypad = ypad.astype(np.float32)\n",
    "    Xs.append(Xpad)\n",
    "    ys.append(ypad)\n",
    "    \n",
    "X = np.stack(Xs)\n",
    "y = np.stack(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383d19d",
   "metadata": {},
   "source": [
    "# Test the pytorch setup for the input X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47b7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a pytorch FCN class for particleflow \n",
    "\n",
    "class MLPF_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Showcase an example of an fully connected network pytorch model, with a skip connection, that can be explained by LRP\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=12, hidden_dim=2, embedding_dim=2, output_dim=2):\n",
    "        super(MLPF_FCN, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU\n",
    "\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim, embedding_dim),\n",
    "        )\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, hidden_dim),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        embedding = self.nn1(X)\n",
    "        return self.nn2(torch.cat([X, embedding], axis=1)), _, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5686536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a pytorch GNN class for particleflow \n",
    "\n",
    "import pickle as pkl\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Union\n",
    "from torch_geometric.typing import OptTensor, PairTensor, PairOptTensor\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader, Batch\n",
    "\n",
    "try:\n",
    "    from torch_cluster import knn\n",
    "except ImportError:\n",
    "    knn = None\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPF_GNN(nn.Module):\n",
    "    \"\"\"\n",
    "    GNN model based on Gravnet...\n",
    "\n",
    "    Forward pass returns\n",
    "        preds: tensor of predictions containing a concatenated representation of the pids and p4\n",
    "        A: dict() object containing adjacency matrices for each message passing\n",
    "        msg_activations: dict() object containing activations before each message passing\n",
    "    \"\"\"\n",
    "import torch\n",
    "from torch import Tensor\n",
    "    def __init__(self,\n",
    "                 input_dim=12, output_dim_id=6, output_dim_p4=6,\n",
    "                 embedding_dim=2, hidden_dim1=2, hidden_dim2=2,\n",
    "                 num_convs=2, space_dim=4, propagate_dim=2, k=8):\n",
    "        super(MLPF_GNN, self).__init__()\n",
    "\n",
    "        # self.act = nn.ReLU\n",
    "        self.act = nn.ELU\n",
    "\n",
    "        # (1) embedding\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim1),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim1),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim1, embedding_dim),\n",
    "        )\n",
    "\n",
    "        self.conv = nn.ModuleList()\n",
    "        for i in range(num_convs):\n",
    "            self.conv.append(GravNetConv_LRP(embedding_dim, embedding_dim, space_dim, propagate_dim, k))\n",
    "\n",
    "        # (3) DNN layer: classifiying pid\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, output_dim_id),\n",
    "        )\n",
    "\n",
    "        # (4) DNN layer: regressing p4\n",
    "        self.nn3 = nn.Sequential(\n",
    "            nn.Linear(input_dim + output_dim_id, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            nn.Linear(hidden_dim2, output_dim_p4),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        x0 = batch.x\n",
    "\n",
    "        # embed the inputs\n",
    "        embedding = self.nn1(x0)\n",
    "\n",
    "        # preform a series of graph convolutions\n",
    "        A = {}\n",
    "        msg_activations = {}\n",
    "        for num, conv in enumerate(self.conv):\n",
    "            embedding, A[f'conv.{num}'], msg_activations[f'conv.{num}'] = conv(embedding)\n",
    "\n",
    "        # predict the pid's\n",
    "        preds_id = self.nn2(torch.cat([x0, embedding], axis=-1))\n",
    "\n",
    "        # predict the p4's\n",
    "        preds_p4 = self.nn3(torch.cat([x0, preds_id], axis=-1))\n",
    "\n",
    "        return torch.cat([preds_id, preds_p4], axis=-1), A, msg_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9feda21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GravNetConv_LRP(MessagePassing):\n",
    "    \"\"\"\n",
    "    Copied from pytorch_geometric source code, with the following edits\n",
    "      a. retrieve adjacency matrix (we call A), and the activations before the message passing step (we call msg_activations)\n",
    "      b. switched the execution of self.lin_s & self.lin_p so that the message passing step can substitute out of the box self.lin_s for lrp purposes\n",
    "      c. used reduce='sum' instead of reduce='mean' in the message passing\n",
    "      d. removed skip connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 space_dimensions: int, propagate_dimensions: int, k: int,\n",
    "                 num_workers: int = 1, **kwargs):\n",
    "        super().__init__(flow='source_to_target', **kwargs)\n",
    "\n",
    "        if knn is None:\n",
    "            raise ImportError('`GravNetConv` requires `torch-cluster`.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.lin_p = Linear(in_channels, propagate_dimensions)\n",
    "        self.lin_s = Linear(in_channels, space_dimensions)\n",
    "        self.lin_out = Linear(propagate_dimensions, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_s.reset_parameters()\n",
    "        self.lin_p.reset_parameters()\n",
    "        self.lin_out.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "            self, x: Union[Tensor, PairTensor],\n",
    "            batch: Union[OptTensor, Optional[PairTensor]] = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        is_bipartite: bool = True\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "            is_bipartite = False\n",
    "\n",
    "        if x[0].dim() != 2:\n",
    "            raise ValueError(\"Static graphs not supported in 'GravNetConv'\")\n",
    "\n",
    "        b: PairOptTensor = (None, None)\n",
    "        if isinstance(batch, Tensor):\n",
    "            b = (batch, batch)\n",
    "        elif isinstance(batch, tuple):\n",
    "            assert batch is not None\n",
    "            b = (batch[0], batch[1])\n",
    "\n",
    "        # embed the inputs before message passing\n",
    "        msg_activations = self.lin_p(x[0])\n",
    "\n",
    "        # transform to the space dimension to build the graph\n",
    "        s_l: Tensor = self.lin_s(x[0])\n",
    "        s_r: Tensor = self.lin_s(x[1]) if is_bipartite else s_l\n",
    "\n",
    "        edge_index = knn(s_l, s_r, self.k, b[0], b[1]).flip([0])\n",
    "\n",
    "        edge_weight = (s_l[edge_index[0]] - s_r[edge_index[1]]).pow(2).sum(-1)\n",
    "        edge_weight = torch.exp(-10. * edge_weight)  # 10 gives a better spread\n",
    "\n",
    "        # return the adjacency matrix of the graph for lrp purposes\n",
    "        A = to_dense_adj(edge_index.to('cpu'), edge_attr=edge_weight.to('cpu'))[0]  # adjacency matrix\n",
    "\n",
    "        # message passing\n",
    "        out = self.propagate(edge_index, x=(msg_activations, None),\n",
    "                             edge_weight=edge_weight,\n",
    "                             size=(s_l.size(0), s_r.size(0)))\n",
    "\n",
    "        return self.lin_out(out), A, msg_activations\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: Tensor) -> Tensor:\n",
    "        return x_j * edge_weight.unsqueeze(1)\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        out_mean = scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                           reduce='sum')\n",
    "        return out_mean\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, k={self.k})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b15315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from X (the input to the tensorflow model, reshape and recast as conveninet pytorch format)\n",
    "pytorch_X = torch.tensor(X[:1].reshape(-1,12)) # the slicX[e [:1] picks up the first event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b3df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple FCN and perform forward pass\n",
    "model = MLPF_FCN()\n",
    "model(pytorch_X);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9f5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a GNN and perform forward pass\n",
    "batch = Batch(x = pytorch_X) # recall GNN takes a batch object\n",
    "model = MLPF_GNN()\n",
    "model(batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67179ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines lrp\n",
    "import pickle as pkl\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3621eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP_MLPF():\n",
    "\n",
    "    \"\"\"\n",
    "    Extends the LRP class to act on graph datasets and GNNs based on the Gravnet layer (e.g. the MLPF model, see models.MLPF)\n",
    "    The main trick is to realize that the \".lin_s\" layers in Gravnet are irrelevant for explanations so shall be skipped\n",
    "    The hack, however, is to substitute them precisely with the message_passing step\n",
    "\n",
    "    Differences from standard LRP\n",
    "        a. Rscores become tensors/graphs of input features per output neuron instead of vectors\n",
    "        b. accomodates message passing steps by using the adjacency matrix as the weight matrix in standard LRP,\n",
    "           and redistributing Rscores over the other dimension (over nodes instead of features)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, model, epsilon):\n",
    "\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.epsilon = epsilon  # for stability reasons in the lrp-epsilon rule (by default: a very small number)\n",
    "\n",
    "        # check if the model has any skip connections to accomodate them\n",
    "        self.skip_connections = self.find_skip_connections()\n",
    "        self.msg_passing_layers = self.find_msg_passing_layers()\n",
    "\n",
    "    \"\"\"\n",
    "    explanation functions\n",
    "    \"\"\"\n",
    "\n",
    "    def explain(self, input, neuron_to_explain):\n",
    "        \"\"\"\n",
    "        Primary function to call on an LRP instance to start explaining predictions.\n",
    "        First, it registers hooks and runs a forward pass on the input.\n",
    "        Then, it attempts to explain the whole model by looping over the layers in the model and invoking the explain_single_layer function.\n",
    "\n",
    "        Args:\n",
    "            input: tensor containing the input sample you wish to explain\n",
    "            neuron_to_explain: the index for a particular neuron in the output layer you wish to explain\n",
    "\n",
    "        Returns:\n",
    "            R_tensor: a tensor/graph containing the relevance scores of the input graph for a particular output neuron\n",
    "            preds: the model predictions of the input (for further plotting/processing purposes only)\n",
    "            input: the input that was explained (for further plotting/processing purposes only)\n",
    "        \"\"\"\n",
    "\n",
    "        # register forward hooks to retrieve intermediate activations\n",
    "        # in simple words, when the forward pass is called, the following dict() will be filled with (key, value) = (\"layer_name\", activations)\n",
    "        activations = {}\n",
    "\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activations[name] = input[0]\n",
    "            return hook\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            # unfold any containers so as to register hooks only for their child modules (equivalently we are demanding type(module) != nn.Sequential))\n",
    "            if ('Linear' in str(type(module))) or ('activation' in str(type(module))) or ('BatchNorm1d' in str(type(module))):\n",
    "                module.register_forward_hook(get_activation(name))\n",
    "\n",
    "        # run a forward pass\n",
    "        self.model.eval()\n",
    "        preds, self.A, self.msg_activations = self.model(input.to(self.device))\n",
    "\n",
    "        # get the activations\n",
    "        self.activations = activations\n",
    "        self.num_layers = len(activations.keys())\n",
    "        self.in_features_dim = self.name2layer(list(activations.keys())[0]).in_features\n",
    "\n",
    "        print(f'Total number of layers: {self.num_layers}')\n",
    "\n",
    "        # initialize Rscores for skip connections (in case there are any)\n",
    "        if len(self.skip_connections) != 0:\n",
    "            self.skip_connections_relevance = 0\n",
    "\n",
    "        # initialize the Rscores tensor using the output predictions\n",
    "        Rscores = preds[:, neuron_to_explain].reshape(-1, 1).detach()\n",
    "\n",
    "        # build the Rtensor which is going to be a whole graph of Rscores per node\n",
    "        R_tensor = torch.zeros([Rscores.shape[0], Rscores.shape[0], Rscores.shape[1]]).to(self.device)\n",
    "        for node in range(R_tensor.shape[0]):\n",
    "            R_tensor[node][node] = Rscores[node]\n",
    "\n",
    "        # loop over layers in the model to propagate Rscores backward\n",
    "        for layer_index in range(self.num_layers, 0, -1):\n",
    "            R_tensor = self.explain_single_layer(R_tensor, layer_index, neuron_to_explain)\n",
    "\n",
    "        print(\"Finished explaining all layers.\")\n",
    "\n",
    "        if len(self.skip_connections) != 0:\n",
    "            return R_tensor + self.skip_connections_relevance, preds, input\n",
    "\n",
    "        return R_tensor, preds, input\n",
    "\n",
    "    def explain_single_layer(self, R_tensor_old, layer_index, neuron_to_explain):\n",
    "        \"\"\"\n",
    "        Attempts to explain a single layer in the model by propagating Rscores backwards using the lrp-epsilon rule.\n",
    "\n",
    "        Args:\n",
    "            R_tensor_old: a tensor/graph containing the Rscores, of the current layer, to be propagated backwards\n",
    "            layer_index: index that corresponds to the position of the layer in the model (see helper functions)\n",
    "            neuron_to_explain: the index for a particular neuron in the output layer to explain\n",
    "\n",
    "        Returns:\n",
    "            R_tensor_new: a tensor/graph containing the computed Rscores of the previous layer\n",
    "        \"\"\"\n",
    "\n",
    "        # get layer information\n",
    "        layer_name = self.index2name(layer_index)\n",
    "        layer = self.name2layer(layer_name)\n",
    "\n",
    "        # get layer activations (depends wether it's a message passing step)\n",
    "        if layer_name in self.msg_passing_layers.keys():\n",
    "            print(f\"Explaining layer {self.num_layers+1-layer_index}/{self.num_layers}: MessagePassing layer\")\n",
    "            input = self.msg_activations[layer_name[:-6]].to(self.device).detach()\n",
    "            msg_passing_layer = True\n",
    "        else:\n",
    "            print(f\"Explaining layer {self.num_layers+1-layer_index}/{self.num_layers}: {layer}\")\n",
    "            input = self.activations[layer_name].to(self.device).detach()\n",
    "            msg_passing_layer = False\n",
    "\n",
    "        # run lrp\n",
    "        if 'Linear' in str(layer):\n",
    "            R_tensor_new = self.eps_rule(self, layer, layer_name, input, R_tensor_old, neuron_to_explain, msg_passing_layer)\n",
    "            print('- Finished computing Rscores')\n",
    "            return R_tensor_new\n",
    "        else:\n",
    "            if 'activation' in str(layer):\n",
    "                print(f\"- skipping layer because it's an activation layer\")\n",
    "            elif 'BatchNorm1d' in str(layer):\n",
    "                print(f\"- skipping layer because it's a BatchNorm layer\")\n",
    "            print(f\"- Rscores do not need to be computed\")\n",
    "            return R_tensor_old\n",
    "\n",
    "    \"\"\"\n",
    "    lrp-epsilon rule\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def eps_rule(self, layer, layer_name, x, R_tensor_old, neuron_to_explain, msg_passing_layer):\n",
    "        \"\"\"\n",
    "        Implements the lrp-epsilon rule presented in the following reference: https://doi.org/10.1007/978-3-030-28954-6_10.\n",
    "\n",
    "        Can accomodate message_passing layers if the adjacency matrix and the activations before the message_passing are provided.\n",
    "        The trick (or as we like to call it, the message_passing hack) is in\n",
    "            a. using the adjacency matrix as the weight matrix in the standard lrp rule\n",
    "            b. transposing the activations to distribute the Rscores over the other dimension (over nodes instead of features)\n",
    "\n",
    "        Args:\n",
    "            layer: a torch.nn module with a corresponding weight matrix W\n",
    "            x: vector containing the activations of the previous layer\n",
    "            R_tensor_old: a tensor/graph containing the Rscores, of the current layer, to be propagated backwards\n",
    "            neuron_to_explain: the index for a particular neuron in the output layer to explain\n",
    "\n",
    "        Returns:\n",
    "            R_tensor_new: a tensor/graph containing the computed Rscores of the previous layer\n",
    "        \"\"\"\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if msg_passing_layer:   # message_passing hack\n",
    "            x = torch.transpose(x, 0, 1)               # transpose the activations to distribute the Rscores over the other dimension (over nodes instead of features)\n",
    "            W = self.A[layer_name[:-6]].detach().to(self.device)       # use the adjacency matrix as the weight matrix\n",
    "        else:\n",
    "            W = layer.weight.detach()  # get weight matrix\n",
    "            W = torch.transpose(W, 0, 1)    # sanity check of forward pass: (torch.matmul(x, W) + layer.bias) == layer(x)\n",
    "\n",
    "        # for the output layer, pick the part of the weight matrix connecting only to the neuron you're attempting to explain\n",
    "        if layer == list(self.model.modules())[-1]:\n",
    "            W = W[:, neuron_to_explain].reshape(-1, 1)\n",
    "\n",
    "        # (1) compute the denominator\n",
    "        denominator = torch.matmul(x, W) + self.epsilon\n",
    "        # (2) scale the Rscores\n",
    "        if msg_passing_layer:  # message_passing hack\n",
    "            R_tensor_old = torch.transpose(R_tensor_old, 1, 2)\n",
    "        scaledR = R_tensor_old / denominator\n",
    "        # (3) compute the new Rscores\n",
    "        R_tensor_new = torch.matmul(scaledR, torch.transpose(W, 0, 1)) * x\n",
    "\n",
    "        # checking conservation of Rscores for a given random node (# 17)\n",
    "        rtol = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "        for tol in rtol:\n",
    "            if (torch.allclose(R_tensor_new[17].sum(), R_tensor_old[17].sum(), rtol=tol)):\n",
    "                print(f'- Rscores are conserved up to relative tolerance {str(tol)}')\n",
    "                break\n",
    "\n",
    "        if layer in self.skip_connections:\n",
    "            # set aside the relevance of the input_features in the skip connection\n",
    "            # recall: it is assumed that the skip connections are defined in the following order torch.cat[(input_features, ...)] )\n",
    "            self.skip_connections_relevance = self.skip_connections_relevance + R_tensor_new[:, :, :self.in_features_dim]\n",
    "            return R_tensor_new[:, :, self.in_features_dim:]\n",
    "\n",
    "        if msg_passing_layer:  # message_passing hack\n",
    "            return torch.transpose(R_tensor_new, 1, 2)\n",
    "\n",
    "        return R_tensor_new\n",
    "\n",
    "    \"\"\"\n",
    "    helper functions\n",
    "    \"\"\"\n",
    "\n",
    "    def index2name(self, layer_index):\n",
    "        \"\"\"\n",
    "        Given the index of a layer (e.g. 3) returns the name of the layer (e.g. .nn1.3)\n",
    "        \"\"\"\n",
    "        layer_name = list(self.activations.keys())[layer_index - 1]\n",
    "        return layer_name\n",
    "\n",
    "    def name2layer(self, layer_name):\n",
    "        \"\"\"\n",
    "        Given the name of a layer (e.g. .nn1.3) returns the corresponding torch module (e.g. Linear(...))\n",
    "        \"\"\"\n",
    "        for name, module in self.model.named_modules():\n",
    "            if layer_name == name:\n",
    "                return module\n",
    "\n",
    "    def find_skip_connections(self):\n",
    "        \"\"\"\n",
    "        Given a torch model, retuns a list of layers with skip connections... the elements are torch modules (e.g. Linear(...))\n",
    "        \"\"\"\n",
    "        explainable_layers = []\n",
    "        for name, module in self.model.named_modules():\n",
    "            if 'lin_s' in name:     # for models that are based on Gravnet, skip the lin_s layers\n",
    "                continue\n",
    "            if ('Linear' in str(type(module))):\n",
    "                explainable_layers.append(module)\n",
    "\n",
    "        skip_connections = []\n",
    "        for layer_index in range(len(explainable_layers) - 1):\n",
    "            if explainable_layers[layer_index].out_features != explainable_layers[layer_index + 1].in_features:\n",
    "                skip_connections.append(explainable_layers[layer_index + 1])\n",
    "\n",
    "        return skip_connections\n",
    "\n",
    "    def find_msg_passing_layers(self):\n",
    "        \"\"\"\n",
    "        Returns a list of \".lin_s\" layers from model.named_modules() that shall be substituted with message passing\n",
    "        \"\"\"\n",
    "        msg_passing_layers = {}\n",
    "        for name, module in self.model.named_modules():\n",
    "            if 'lin_s' in name:     # for models that are based on Gravnet, replace the .lin_s layers with message_passing\n",
    "                msg_passing_layers[name] = {}\n",
    "\n",
    "        return msg_passing_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e40332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers: 13\n",
      "Explaining layer 1/13: Linear(in_features=2, out_features=2, bias=True)\n",
      "- Rscores are conserved up to relative tolerance 1e-05\n",
      "- Finished computing Rscores\n",
      "Explaining layer 2/13: ReLU()\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 3/13: Linear(in_features=14, out_features=2, bias=True)\n",
      "- Rscores are conserved up to relative tolerance 1e-05\n",
      "- Finished computing Rscores\n",
      "Explaining layer 4/13: Linear(in_features=2, out_features=2, bias=True)\n",
      "- Finished computing Rscores\n",
      "Explaining layer 5/13: ReLU()\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 6/13: BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "- skipping layer because it's a BatchNorm layer\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 7/13: Linear(in_features=2, out_features=2, bias=True)\n",
      "- Rscores are conserved up to relative tolerance 1e-05\n",
      "- Finished computing Rscores\n",
      "Explaining layer 8/13: ReLU()\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 9/13: BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "- skipping layer because it's a BatchNorm layer\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 10/13: Linear(in_features=2, out_features=2, bias=True)\n",
      "- Rscores are conserved up to relative tolerance 1e-05\n",
      "- Finished computing Rscores\n",
      "Explaining layer 11/13: ReLU()\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 12/13: BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "- skipping layer because it's a BatchNorm layer\n",
      "- Rscores do not need to be computed\n",
      "Explaining layer 13/13: Linear(in_features=12, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# test lrp for the FCN model\n",
    "model = MLPF_FCN()\n",
    "\n",
    "lrp_instance = LRP_MLPF('cpu', model, epsilon=1e-9)\n",
    "Rtensor, pred, inputt = lrp_instance.explain(pytorch_X, neuron_to_explain=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19daf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPF_GNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test lrp for the GNN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMLPF_GNN\u001b[49m()\n\u001b[1;32m      4\u001b[0m lrp_instance \u001b[38;5;241m=\u001b[39m LRP_MLPF(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, model, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n\u001b[1;32m      5\u001b[0m Rtensor, pred, inputt \u001b[38;5;241m=\u001b[39m lrp_instance\u001b[38;5;241m.\u001b[39mexplain(batch, neuron_to_explain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPF_GNN' is not defined"
     ]
    }
   ],
   "source": [
    "# test lrp for the GNN model\n",
    "model = MLPF_GNN()\n",
    "\n",
    "lrp_instance = LRP_MLPF('cpu', model, epsilon=1e-9)\n",
    "Rtensor, pred, inputt = lrp_instance.explain(batch, neuron_to_explain=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937bff8",
   "metadata": {},
   "source": [
    "# Back to the tensorflow setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d8898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first event\n",
    "input_classes = np.unique(X[:, :, 0].flatten())\n",
    "output_classes = np.unique(y[:, :, 0].flatten())\n",
    "num_output_classes = len(output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ab1b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b36a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f66e909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 11:49:11.398075: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "def transform_target(y):\n",
    "    return {\n",
    "        \"cls\": tf.one_hot(tf.cast(y[:, :, 0], tf.int32), num_output_classes),\n",
    "        \"charge\": y[:, :, 1:2],\n",
    "        \"pt\": y[:, :, 2:3],\n",
    "        \"eta\": y[:, :, 3:4],\n",
    "        \"sin_phi\": y[:, :, 4:5],\n",
    "        \"cos_phi\": y[:, :, 5:6],\n",
    "        \"energy\": y[:, :, 6:7],\n",
    "    }\n",
    "yt = transform_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18277925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfmodel.model import PFNetDense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a48b8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_true_particle = y[:, :, 0]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2ae5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.], dtype=float32),\n",
       " array([263996,  93508, 133732,    912,    278]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y[msk_true_particle][:, 0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975612c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yt[\"pt\"][msk_true_particle].flatten(), bins=100);\n",
    "plt.xlabel(\"pt\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7de9180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'eta')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yt[\"eta\"][msk_true_particle].flatten(), bins=100);\n",
    "plt.xlabel(\"eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b73fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'sin phi')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yt[\"sin_phi\"][msk_true_particle].flatten(), bins=100);\n",
    "plt.xlabel(\"sin phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a490954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'cos phi')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yt[\"cos_phi\"][msk_true_particle].flatten(), bins=100);\n",
    "plt.xlabel(\"cos phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "669b39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAARkUlEQVR4nO3df4ycR33H8fcHU6dVgAiwociJsWmiCKtSgRyhFIQiFagDNabQ0hiqQhXFQqoL/QMJI5AAVUhQ9YdApAGXWAGEElmQUBtME5SCDFIodtIQ4lgpJg3KkYgYglxAqG7Ct3/sOtmeb+3d2z3v7ez7JZ3u2dnneXZ2tP567juzM6kqJEltedKkKyBJGj+DuyQ1yOAuSQ0yuEtSgwzuktSgJ0+6AgBr1qypDRs2TLoakjRVbr/99h9X1drFnlsRwX3Dhg0cOnRo0tWQpKmS5Af9nptoWibJliS7jh8/PslqSFJzJhrcq2pfVW0/77zzJlkNSWqOA6qS1CDTMpLUINMyktQg0zKS1CCDuyQ1yJy7JDVool9iqqp9wL65ubmrlnqPDTu//Pjx/R9+7TiqJUlTz7SMJDXI4C5JDTLnLkkNcp67JDXItIwkNcjgLkkNMrhLUoMM7pLUIGfLSFKDnC0jSQ0yLSNJDTK4S1KDDO6S1CCDuyQ1yOAuSQ0yuEtSg8Ye3JNcluQbST6R5LJx31+SdGYDBfcku5M8nOTuBeWbk9yb5GiSnd3iAn4O/DowP97qSpIGMWjP/Tpgc29BklXA1cDlwCZgW5JNwDeq6nLg3cAHx1dVSdKgBgruVXUAeGRB8aXA0aq6r6pOADcAW6vqV93nfwqc0++eSbYnOZTk0LFjx5ZQdUlSP6Pk3NcBD/Q8ngfWJXlDkk8CnwU+3u/iqtpVVXNVNbd27doRqiFJWujJI1ybRcqqqm4EbhzoBskWYMuFF144QjUkSQuN0nOfBy7oeXw+8OAwN3DhMElaHqME94PARUk2JlkNXAHsHeYGLvkrSctj0KmQ1wO3ARcnmU9yZVU9CuwAbgaOAHuq6vAwL27PXZKWx0A596ra1qd8P7B/qS9uzl2SloebdUhSg9xmT5IaZM9dkhrkqpCS1CDTMpLUINMyktQg0zKS1CDTMpLUINMyktQg0zKS1KBRlvxdcTbs/PLjx/d/+LUTrIkkTZY9d0lqkAOqktSgiaZlqmofsG9ubu6qcd/bFI2kWWZaRpIaZHCXpAYZ3CWpQQZ3SWrQRAdUz9Y2ew6uSpo1Lj8gSQ0yLSNJDTK4S1KDDO6S1CCDuyQ1yOAuSQ1alqmQSc4FDgDvr6ovLcdrLJXTIiXNgoF67kl2J3k4yd0LyjcnuTfJ0SQ7e556N7BnnBWVJA1u0LTMdcDm3oIkq4CrgcuBTcC2JJuSvBK4B/jRGOspSRrCQGmZqjqQZMOC4kuBo1V1H0CSG4CtwFOAc+kE/F8m2V9VvxpflSVJZzJKzn0d8EDP43ngJVW1AyDJ24Af9wvsSbYD2wHWr18/QjUkSQuNEtyzSFk9flB13ekurqpdSR4CtqxevfqSEeohSVpglOA+D1zQ8/h84MFhbrCcOzENonfmDDh7RlI7RpnnfhC4KMnGJKuBK4C9w9zAPVQlaXkMOhXyeuA24OIk80murKpHgR3AzcARYE9VHR7mxV0VUpKWx6CzZbb1Kd8P7F/qi5+t9dwlada4nrskNWiiOzGtNC5NIKkVE+25O6AqScvDtIwkNcieuyQ1yJ67JDXIzTokqUHOlunDmTOSppk5d0lqkDl3SWqQOXdJapDBXZIaNNEB1WlZOMzBVUnTxpy7JDXItIwkNcjgLkkNMrhLUoP8huqQHFyVNA3suUtSg1x+QJIa5FRISWqQOfcRmH+XtFKZc5ekBhncJalBBndJapDBXZIaNPYB1STPB94JrAFuraprxv0aK5GDq5JWkoF67kl2J3k4yd0LyjcnuTfJ0SQ7AarqSFW9HXgTMDf+KkuSzmTQtMx1wObegiSrgKuBy4FNwLYkm7rPvQ74JnDr2GoqSRrYQMG9qg4AjywovhQ4WlX3VdUJ4AZga/f8vVX1e8Bb+t0zyfYkh5IcOnbs2NJqL0la1Cg593XAAz2P54GXJLkMeANwDrC/38VVtQvYBTA3N1cj1GPFMf8uadJGCe5ZpKyq6uvA1we6wZRssydJ02aUqZDzwAU9j88HHhzmBq4tI0nLY5Se+0HgoiQbgR8CVwBvHuYGs9BzN0UjaRIGnQp5PXAbcHGS+SRXVtWjwA7gZuAIsKeqDg/z4vbcJWl5DNRzr6ptfcr3c5pB0zOZhZ67JE3CRJf8rap9wL65ubmrJlmPs8UUjaSzxZ2YJKlB7sQkSQ1yVUhJatBEc+6zPKBq/l3ScjItI0kNcoPsFcBevKRxc7aMJDXIee4rjL14SePgbBlJapDBXZIa5IDqCtaboullukbSmTigKkkNckB1CjnoKulMzLlLUoMM7pLUIAdUp1y/Qddepm6k2WNwnwHm6KXZ42wZSWqQs2Vm2Kg9ev8ikFYu0zIzpl+O3kAttcXgrlOcbpDWwC9NB4O7hjLI7Bz/CpAmz+CusRgk6Es6ewzumgh799LyMrjrrLF3L509yxLck7weeC3wLODqqrplOV5HK585emkyBg7uSXYDfwg8XFW/3VO+GfgosAr4VFV9uKq+CHwxydOBvwMM7hqIgV4aj2G+oXodsLm3IMkq4GrgcmATsC3Jpp5T3td9XpJ0Fg0c3KvqAPDIguJLgaNVdV9VnQBuALam4yPAV6rqjsXul2R7kkNJDh07dmyp9ZckLWLUnPs64IGex/PAS4C/Al4JnJfkwqr6xMILq2pXkoeALatXr75kxHqocaZrpOGMGtyzSFlV1ceAj53pYteW0VIY6KUzGzW4zwMX9Dw+H3hw0IuTbAG2XHjhhSNWQ7PKQC8tbtTgfhC4KMlG4IfAFcCbB73YnrtOx3nx0tINMxXyeuAyYE2SeeD9VXVtkh3AzXSmQu6uqsND3NOeu8bGXrz0hIGDe1Vt61O+H9i/lBe35y5Jy8MNsiWpQRNdW8a0jJZLv3y96RrNCrfZ00wxL69ZYVpGkho00eCeZEuSXcePH59kNSSpORMN7lW1r6q2n3feeZOshiQ1x806NLPMv6tlzpaRFjDoqwXOlpFwqQO1x9kyktQgc+7SgBb27k3ZaCVzKqQkNcicu3Qa5uI1rcy5S1KDzLlLY+D0Sa009twlqUEGd0lqkMFdkhrk8gPSEjmTRiuZq0JKUoNMy0hSgwzuktQgg7skNcgvMUlj5heatBLYc5ekBo09uCd5XpJrk3x+3PeWJA1moOCeZHeSh5PcvaB8c5J7kxxNshOgqu6rqiuXo7LSNNuw88uP/0jLbdCc+3XAx4HPnCxIsgq4GngVMA8cTLK3qu4ZdyWl1piX13IbKLhX1YEkGxYUXwocrar7AJLcAGwFBgruSbYD2wHWr18/aH2lmeF/ABrFKDn3dcADPY/ngXVJnpnkE8ALk7yn38VVtauq5qpqbu3atSNUQ5K00ChTIbNIWVXVT4C3D3QD15ZR4yaVX+/X6/evgdkxSs99Hrig5/H5wIPD3MC1ZSRpeYwS3A8CFyXZmGQ1cAWwd5gbuEG2JC2PQadCXg/cBlycZD7JlVX1KLADuBk4AuypqsPDvLg9d0laHoPOltnWp3w/sH+pL27OXTIPruXheu6S1KCJBndz7pK0POy5S1KDXBVSkhrkBtnSlHHhMQ3CtIwkNci0jCQ1yOAuSQ0y5y5NAfPsGpY5d0lqkGkZSWqQwV2SGmTOXVpBzK1rXMy5S1KDTMtIUoMM7pLUIIO7JDXI4C5JDXK2jNS4QWbg9Dun37Z/bg248jlbRpIaZFpGkhpkcJekBhncJalBBndJapDBXZIaZHCXpAaNfZ57knOBfwJOAF+vqs+N+zUkSac3UM89ye4kDye5e0H55iT3JjmaZGe3+A3A56vqKuB1Y66vJGkAg6ZlrgM29xYkWQVcDVwObAK2JdkEnA880D3tsfFUU5I0jIHSMlV1IMmGBcWXAker6j6AJDcAW4F5OgH+Tk7zn0eS7cB2gPXr1w9bb0kjGtfGIAvv07scQb9lCgZZvmDYJRHOplGXXzgbyzeMMqC6jid66NAJ6uuAG4E3JrkG2Nfv4qraVVVzVTW3du3aEaohSVpolAHVLFJWVfUL4C8GuoELh0nSshil5z4PXNDz+HzgwdGqI0kah1GC+0HgoiQbk6wGrgD2DnMDV4WUpOUx6FTI64HbgIuTzCe5sqoeBXYANwNHgD1VdXiYF0+yJcmu48ePD1tvSdJpDDpbZluf8v3A/qW+eFXtA/bNzc1dtdR7SJJO5fIDktSgiQZ30zKStDzcZk+SGpSqmnQdSHIM+MESL18D/HiM1WmF7XIq22RxtsuppqVNnltVi34LdEUE91EkOVRVc5Oux0pju5zKNlmc7XKqFtrEAVVJapDBXZIa1EJw3zXpCqxQtsupbJPF2S6nmvo2mfqcuyTpVC303CVJCxjcJalBUx3c++zhOhOS3J/ku0nuTHKoW/aMJF9N8r3u76f3nP+ebjvdm+QPJlfz8Vpsf9+ltEOSS7rteTTJx5Istl/BVOjTJh9I8sPu5+XOJK/peW4W2uSCJF9LciTJ4STv7Ja3+1mpqqn8AVYB3weeB6wGvgNsmnS9zuL7vx9Ys6Dsb4Gd3eOdwEe6x5u67XMOsLHbbqsm/R7G1A6vAF4E3D1KOwDfBl5KZxOarwCXT/q9jblNPgC8a5FzZ6VNngO8qHv8VOA/u++92c/KNPfcH9/DtapOACf3cJ1lW4FPd48/Dby+p/yGqvqfqvov4Cid9pt6VXUAeGRB8VDtkOQ5wNOq6rbq/Ov9TM81U6dPm/QzK23yUFXd0T3+GZ1lytfR8GdlmoN7vz1cZ0UBtyS5vbvZOMCzq+oh6HyYgWd1y2etrYZth3Xd44XlrdmR5K5u2uZk+mHm2iTJBuCFwL/T8GdlmoP7onu4nvVaTM7LqupFwOXAXyZ5xWnOnfW2OqlfO8xC+1wD/BbwAuAh4O+75TPVJkmeAnwB+Ouq+u/TnbpI2VS1yzQH95new7WqHuz+fhi4iU6a5UfdPxvp/n64e/qstdWw7TDfPV5Y3oyq+lFVPVZVvwL+mSfScjPTJkl+jU5g/1xV3dgtbvazMs3BfeQ9XKdVknOTPPXkMfBq4G467/+t3dPeCvxL93gvcEWSc5JsBC6iMyjUqqHaofvn+M+S/G535sOf91zThJMBrOuP6HxeYEbapPsergWOVNU/9DzV7mdl0iO6o/wAr6Ez6v194L2Trs9ZfN/PozOS/x3g8Mn3DjwTuBX4Xvf3M3queW+3ne5lhY7uL7EtrqeTZvhfOr2qK5fSDsAcnYD3feDjdL+9PY0/fdrks8B3gbvoBK7nzFibvJxO+uQu4M7uz2ta/qy4/IAkNWia0zKSpD4M7pLUIIO7JDXI4C5JDTK4S1KDDO6S1CCDuzSkJE+edB2kMzG4q3lJ/izJt7vrmH8yyaokP0/yoSTfSfKtJM/unrs2yReSHOz+vKxb/oEku5LcAnyme95Xk9zRvecPkqxJ8jcn1wrvXvehJO+Y0FvXDDO4q2lJng/8KZ2F1l4APAa8BTgX+FZV/Q5wALiqe8lHgX+sqhcDbwQ+1XO7S4CtVfVm4P3Av1Vn8babgPXdc66l+3X2JE+isyzG55btDUp9+OelWvf7dILywe6GOb9BZ3GoE8CXuufcDryqe/xKYFPP5jpPO7mOD7C3qn7ZPX45nTVaqKp/TfLT7vH9SX6S5IXAs4H/qKqfLNebk/oxuKt1AT5dVe/5f4XJu+qJtTce44l/C08CXtoTxE+eD/CLBfft51PA24DfBHYvuebSCEzLqHW3An+c5Fnw+J6Zzz3N+bcAO04+SPKCPud9E3hT95xXA0/vee4mYDPwYuDmJddcGoHBXU2rqnuA99HZteou4Kt09tPs5x3AXHfHonuAt/c574PAq5PcQWfDlIeAn3Vf8wTwNWBPVT02nnciDcdVIaUlSHIO8FhVPZrkpcA13QHbkwOpdwB/UlXfm2A1NcPMuUtLsx7Y0w3kJ+jOtkmyic5A7U0Gdk2SPXdJapA5d0lqkMFdkhpkcJekBhncJalBBndJatD/ASo5rIB/VeXCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yt[\"energy\"][msk_true_particle].flatten(), bins=100);\n",
    "plt.xlabel(\"energy\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58838785",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPFNetDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_input_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_output_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UCSD/particleflow/mlpf/tfmodel/model.py:795\u001b[0m, in \u001b[0;36mPFNetDense.__init__\u001b[0;34m(self, do_node_encoding, node_encoding_hidden_dim, dropout, activation, multi_output, num_input_classes, num_output_classes, num_graph_layers_id, num_graph_layers_reg, input_encoding, skip_connection, graph_kernel, combined_graph_layer, node_message, output_decoding, debug, schema, node_update_mode, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m dropout\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_update_mode \u001b[38;5;241m=\u001b[39m node_update_mode\n\u001b[0;32m--> 795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_node_encoding:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoding \u001b[38;5;241m=\u001b[39m point_wise_feed_forward_network(\n\u001b[1;32m    799\u001b[0m         combined_graph_layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_message\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoding_hidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m         dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout\n\u001b[1;32m    805\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "model = PFNetDense(\n",
    "    num_input_classes=len(input_classes),\n",
    "    num_output_classes=len(output_classes),\n",
    "    activation=tf.nn.elu,\n",
    "    hidden_dim=128,\n",
    "    bin_size=128,\n",
    "    input_encoding=\"default\",\n",
    "    multi_output=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92f00649",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPFNetDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_input_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_output_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# #temporal weight mode means each input element in the event can get a separate weight\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     sample_weight_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/UCSD/particleflow/mlpf/tfmodel/model.py:795\u001b[0m, in \u001b[0;36mPFNetDense.__init__\u001b[0;34m(self, do_node_encoding, node_encoding_hidden_dim, dropout, activation, multi_output, num_input_classes, num_output_classes, num_graph_layers_id, num_graph_layers_reg, input_encoding, skip_connection, graph_kernel, combined_graph_layer, node_message, output_decoding, debug, schema, node_update_mode, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m dropout\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_update_mode \u001b[38;5;241m=\u001b[39m node_update_mode\n\u001b[0;32m--> 795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_node_encoding:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoding \u001b[38;5;241m=\u001b[39m point_wise_feed_forward_network(\n\u001b[1;32m    799\u001b[0m         combined_graph_layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_message\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoding_hidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m         dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout\n\u001b[1;32m    805\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "model = PFNetDense(\n",
    "    num_input_classes=len(input_classes),\n",
    "    num_output_classes=len(output_classes),\n",
    "    activation=tf.nn.elu,\n",
    "    hidden_dim=128,\n",
    "    bin_size=128,\n",
    "    input_encoding=\"default\",\n",
    "    multi_output=True,\n",
    ")\n",
    "\n",
    "# #temporal weight mode means each input element in the event can get a separate weight\n",
    "model.compile(\n",
    "    loss={\n",
    "        \"cls\": tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        \"charge\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"pt\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"energy\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"eta\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"sin_phi\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"cos_phi\": tf.keras.losses.MeanSquaredError()\n",
    "    },\n",
    "    optimizer=\"adam\",\n",
    "    sample_weight_mode=\"temporal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "170aaea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ea41093cc700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-af3e6a87d2e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "model(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86112b38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPF_FCN' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-78c52f5201cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPF_FCN' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model.fit(X, yt, epochs=2, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a426d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPF_FCN' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-be0678ea91d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_98py3cu10/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPF_FCN' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39e67efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b0ea429445ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#index of the class prediction output values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_id_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mypred_ids_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ypred' is not defined"
     ]
    }
   ],
   "source": [
    "#index of the class prediction output values\n",
    "pred_id_offset = len(output_classes)\n",
    "ypred_ids_raw = ypred[\"cls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6314c62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypred_ids_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a5d489b094eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m sklearn.metrics.confusion_matrix(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred_ids_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ypred_ids_raw' is not defined"
     ]
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(\n",
    "    np.argmax(ypred_ids_raw, axis=-1).flatten(),\n",
    "    np.argmax(yt[\"cls\"], axis=-1).flatten(), labels=output_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49c511ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7e173b4d3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmsk_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m plt.scatter(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mypred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsk_particles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     yt[\"eta\"][msk_particles].flatten(), marker=\".\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ypred' is not defined"
     ]
    }
   ],
   "source": [
    "msk_particles = (X[:, :, 0]!=0)\n",
    "plt.scatter(\n",
    "    ypred[\"eta\"][msk_particles].flatten(),\n",
    "    yt[\"eta\"][msk_particles].flatten(), marker=\".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
