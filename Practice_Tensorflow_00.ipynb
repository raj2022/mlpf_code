{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc90ee07",
   "metadata": {},
   "source": [
    "Writing the mlpf code  in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d3f9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.nn as nn\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d10643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacf01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['/home/sraj/UCSD/particleflow/mlpf/']\n",
    "\n",
    "import tfmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274efacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘tev14_pythia8_ttbar_0_0.pkl.bz2’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate -nc https://zenodo.org/record/4452283/files/tev14_pythia8_ttbar_0_0.pkl.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f59894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(bz2.BZ2File(\"tev14_pythia8_ttbar_0_0.pkl.bz2\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb75f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 100 events in one file\n",
    "len(data['X']), len(data['ygen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pad the number of elements to a size that's divisible by the bins\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "max_size = 50*128\n",
    "\n",
    "for i in range(len(data['X'])):\n",
    "    X = data['X'][i][:max_size, :]\n",
    "    y = data['ygen'][i][:max_size, :]\n",
    "    Xpad = np.pad(X,[(0, max_size - X.shape[0]), (0,0)])\n",
    "    ypad = np.pad(y, [(0, max_size - y. shape[0]), (0,0)])\n",
    "    Xpad = Xpad.astype(np.float32)\n",
    "    ypad = ypad.astype(np.float32)\n",
    "    Xs.append(Xpad)\n",
    "    ys.append(ypad)\n",
    "    \n",
    "X = np.stack(Xs)\n",
    "y = np.stack(ys)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22525416",
   "metadata": {},
   "source": [
    "## Defining a tensorflow FCN class for particleflow\n",
    "Converting the pytorcgh into tensorflow, using this method which can be found using this link. link can be found [here](https://stackoverflow.com/questions/69148722/what-is-the-alias-to-pytorch-nn-module-in-tensorflow)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f4c9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPF_FCN(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim = 12, hidden_dim = 2, embedding_dim=2, output_dim = 2):\n",
    "        super (MLPF_FCN, self).__init__()\n",
    "        \n",
    "        self.act = tf.nn.relu\n",
    "        \n",
    "        self.nn1 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.BatchNormalization(hidden_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, hidden_dim),\n",
    "            tf.keras.BatchNormalization(hidden_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        self.nn2 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim+embedding_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim, output_dim),\n",
    "        \n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        embedding = self.nn1(X)\n",
    "        return self.nn2(tf.concat([X, embedding], axis=1)), _, _\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13892054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the tensorflow GNN class for particleflow\n",
    "import pickle as pkl\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "from typing import Optional, Union\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dca2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPF_GNN(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    GNN model based on Gravnet...\n",
    "\n",
    "    Forward pass returns\n",
    "        preds: tensor of predictions containing a concatenated representation of the pids and p4\n",
    "        A: dict() object containing adjacency matrices for each message passing\n",
    "        msg_activations: dict() object containing activations before each message passing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim =12, output_dim_id = 6, output_dim_p4 = 6, \n",
    "                embedding_dim = 2, hiddn_dim1 = 2, hidden_dim2 = 2, \n",
    "                num_convs=2, space_dim = 4, propagate_dim=2, k=8):\n",
    "        super(MLPF_GNN, self).__init__()\n",
    "        \n",
    "        self.act = tf.nn.elu\n",
    "        \n",
    "        #(1) embedding\n",
    "        \n",
    "        self.nn1 = tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, hiddn_dim1),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, hiddn_dim1),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim1, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        self.conv = tf.keras.layers.Layer()\n",
    "        for i in range(num_convs):\n",
    "            slef.conv.append(GravNetConv_LRP(embedding_dim, embedding_dim, space_dim, propagate_dim, k))\n",
    "            \n",
    "            \n",
    "        ##(3) DNN layer: classifying pid \n",
    "        self.nn2 =  tf.keras.Sequential(\n",
    "            tf.keras.layers.Dense(input_dim+embedding_dim),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, hiddn_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, hiddn_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hiddn_dim2, embedding_dim),      \n",
    "        )\n",
    "            \n",
    "       # (4) DNN layer: regressing p4\n",
    "        self.nn3 = tf.keras.Sequentiall(\n",
    "            tf.keras.layers.Dense(input_dim + output_dim_id),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, hidden_dim2),\n",
    "            self.act(),\n",
    "            tf.keras.layers.Dense(hidden_dim2, output_dim_p4),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x0 = batch.x\n",
    "        \n",
    "        # embed the inputs\n",
    "        embedding = self.nn1(x0)\n",
    "        \n",
    "        # perform a series of graph convolutions\n",
    "        A = {}\n",
    "        msg_activations ={}\n",
    "        for num, conv in enumerate(self.conv):\n",
    "            embedding, A[f'conv.{num}'], msg_activations[f'conv.{num}'] = conv(embedding)\n",
    "        \n",
    "        # predict the pid's\n",
    "        preds_id = self.nn2(tf.concat([x0, embedding], axis=-1))\n",
    "        \n",
    "        # predict the p4's\n",
    "        preds_p4 = self.nn3(tf.concat([x0, preds_id], axis=-1))\n",
    "        \n",
    "        return tf.concat([preds_id, preds_p4], axis= -1), A,  msg_activations         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb9d72",
   "metadata": {},
   "source": [
    "**Defining the message passing here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b8a62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def message_passing(nodes, edges, edge_features, message_fn, edge_keep_prob=1.0):\n",
    "    \"\"\"\n",
    "    Pass messages between nodes and sum the incoming messages at each node.\n",
    "    Implements equation 1 and 2 in the paper, i.e. m_{.j}^t &= \\sum_{i \\in N(j)} f(h_i^{t-1}, h_j^{t-1})\n",
    "    :param nodes: (n_nodes, n_features) tensor of node hidden states.\n",
    "    :param edges: (n_edges, 2) tensor of indices (i, j) indicating an edge from nodes[i] to nodes[j].\n",
    "    :param edge_features: features for each edge. Set to zero if the edges don't have features.\n",
    "    :param message_fn: message function, will be called with input of shape (n_edges, 2*n_features + edge_features). The output shape is (n_edges, n_outputs), where you decide the size of n_outputs\n",
    "    :param edge_keep_prob: The probability by which edges are kept. Basically dropout for edges. Not used in the paper.\n",
    "    :return: (n_nodes, n_output) Sum of messages arriving at each node.\n",
    "    \"\"\"\n",
    "    n_nodes = tf.shape(nodes)[0]\n",
    "    n_features = nodes.get_shape()[1].value\n",
    "    n_edges = tf.shape(edges)[0]\n",
    "\n",
    "    message_inputs = tf.gather(nodes, edges)  # n_edges, 2, n_features\n",
    "    reshaped = tf.concat([tf.reshape(message_inputs, (-1, 2 * n_features)), edge_features], 1)\n",
    "    messages = message_fn(reshaped)  # n_edges, n_output\n",
    "    messages = tf.nn.dropout(messages, edge_keep_prob, noise_shape=(n_edges, 1))\n",
    "\n",
    "    updates = tf.unsorted_segment_sum(messages, edges[:, 1], n_nodes)\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f93fe45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GravNet_Conv_LRP(MessagePassing):\n",
    "    \"\"\"\n",
    "    Copied from pytorch_geometric source code, with the following edits\n",
    "      a. retrieve adjacency matrix (we call A), and the activations before the message passing step (we call msg_activations)\n",
    "      b. switched the execution of self.lin_s & self.lin_p so that the message passing step can substitute out of the box self.lin_s for lrp purposes\n",
    "      c. used reduce='sum' instead of reduce='mean' in the message passing\n",
    "      d. removed skip connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                space_dimensions: int, propagate_dimensions: int, k:int,\n",
    "                num_workers: int = 1, **kwargs):\n",
    "        super().__init__(flow = 'source_to_target', **kwargs)\n",
    "        \n",
    "        if knn is None:\n",
    "            raise ImportError('`GravNetConv` not properly defined.')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.lin_p = Linear(in_channels, propagate_dimensions)\n",
    "        self.lin_s = Linear(in_channels, space_dimensions)\n",
    "        self.lin_out = Linear(propagate_dimensions, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_s.reset_parameters()\n",
    "        self.lin_p.reset_parameters()\n",
    "        self.lin_out.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "            self, x: Union[Tensor, PairTensor],\n",
    "            batch: Union[OptTensor, Optional[PairTensor]] = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        is_bipartite: bool = True\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "            is_bipartite = False\n",
    "\n",
    "        if x[0].dim() != 2:\n",
    "            raise ValueError(\"Static graphs not supported in 'GravNetConv'\")\n",
    "\n",
    "        b: PairOptTensor = (None, None)\n",
    "        if isinstance(batch, Tensor):\n",
    "            b = (batch, batch)\n",
    "        elif isinstance(batch, tuple):\n",
    "            assert batch is not None\n",
    "            b = (batch[0], batch[1])\n",
    "            \n",
    "        # embed the inputs before message passing\n",
    "        msg_activations = self.lin_p(x[0])\n",
    "        \n",
    "        #Transform to space dimension to build the graph\n",
    "        s_l: Tensor = self.lin_s(x[0])\n",
    "        s_r: Tensor = self.lin_s(x[1]) if is_bipartite else s_l\n",
    "            \n",
    "        edge_index = knn(s_l, s_r, self.k, b[0], b[1]).flip([0])\n",
    "        \n",
    "        edge_weight = (s_l[edge_index[0]] - s_r[edge_index[1]]).pow(2).sum(-1)\n",
    "        edge_weight = tf.exp(-10. * edge_weight)   \n",
    "        \n",
    "        # return the adjecency matrix\n",
    "        A = tf.nn.layer.graph_convolution.feature_steered_convolution_layer (edge_index.to('cpu'), edge_attr=edge_weight.to('cpu'))[0]\n",
    "        \n",
    "        #message passing\n",
    "        \n",
    "        out = self.propagate(edge_index, x = (msg_activations, None),\n",
    "                             edge_weight=edge_weight,\n",
    "                             size = (s_l.size(0), s_r.size(0)))\n",
    "        return self.lin_out(out), A, msg_activations\n",
    "    \n",
    "    def message(self, x_j: Tensor, index: Tensor)-> Tensor:\n",
    "        return x_j * edge_weight.unsqueeze(1)\n",
    "    \n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        out_mean = scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                           reduce='sum')\n",
    "        return out_mean\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, k={self.k})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318283a3",
   "metadata": {},
   "source": [
    "***REF* for GCN** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913520c9",
   "metadata": {},
   "source": [
    "1. https://colab.research.google.com/drive/1zi_tPMVHspjUuN3HdHcBwegxYgZyQ5LS#scrollTo=3FEg5eu51c3O\n",
    "2. https://github.com/aimat-lab/gcnn_keras\n",
    "3. https://github.com/tensorflow/graphics/blob/master/tensorflow_graphics/nn/layer/graph_convolution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a37545f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "# from X (the input to the tensorflow model, reshape and recast as conveninet pytorch format)\n",
    "# ...doing\n",
    "pytorch_X = torch.tensor(X[:1].reshape(-1,12)) # the slicX[e [:1] picks up the first event\n",
    "tf_tensor = tf.convert_to_tensor(pytorch_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "948300a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "relu() missing 1 required positional argument: 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# build a simple FCN and perform forward pass\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMLPF_FCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model(tf_tensor)\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mMLPF_FCN.__init__\u001b[0;34m(self, input_dim, hidden_dim, embedding_dim, output_dim)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m (MLPF_FCN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(input_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization(hidden_dim),\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     11\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(hidden_dim, hidden_dim),\n\u001b[1;32m     12\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mBatchNormalization(hidden_dim),\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(),\n\u001b[1;32m     14\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(hidden_dim, embedding_dim),\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     18\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(input_dim\u001b[38;5;241m+\u001b[39membedding_dim),\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(),\n\u001b[1;32m     20\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(hidden_dim, output_dim),\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: relu() missing 1 required positional argument: 'features'"
     ]
    }
   ],
   "source": [
    "# build a simple FCN and perform forward pass\n",
    "model = MLPF_FCN()\n",
    "model(tf_tensor);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a53d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab885f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
